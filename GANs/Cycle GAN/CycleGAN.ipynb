{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cycle GAN Implementation","metadata":{}},{"cell_type":"markdown","source":"## Dependencies","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nfrom tqdm import tqdm\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import save_image","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-08-16T10:58:12.083427Z","iopub.execute_input":"2023-08-16T10:58:12.083902Z","iopub.status.idle":"2023-08-16T10:58:14.682224Z","shell.execute_reply.started":"2023-08-16T10:58:12.083858Z","shell.execute_reply":"2023-08-16T10:58:14.681243Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"def save_checkpoint(filename, model, optimizer):\n    print(\"=> Saving checkpoint\")\n    checkpoint = {\n        \"state_dict\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, filename)\n\n\ndef load_checkpoint(filename, model, optimizer, lr, device):\n    print(\"=> Loading checkpoint\")\n    checkpoint = torch.load(filename, map_location=device)\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-08-16T10:58:14.684377Z","iopub.execute_input":"2023-08-16T10:58:14.684913Z","iopub.status.idle":"2023-08-16T10:58:14.693617Z","shell.execute_reply.started":"2023-08-16T10:58:14.684886Z","shell.execute_reply":"2023-08-16T10:58:14.692638Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, root1, root2, trans=None):\n        self.root1 = root1\n        self.root2 = root2\n        self.trans = trans\n\n        self.images1 = os.listdir(root1)\n        self.images2 = os.listdir(root2)\n\n        self.len1 = len(self.images1)\n        self.len2 = len(self.images2)\n\n    def __len__(self):\n        return max(self.len1, self.len2)\n\n    def __getitem__(self, index):\n        img1 = self.images1[index % self.len1]\n        img2 = self.images2[index % self.len2]\n\n        path1 = os.path.join(self.root1, img1)\n        path2 = os.path.join(self.root2, img2)\n\n        img1 = np.array(Image.open(path1).convert('RGB'))\n        img2 = np.array(Image.open(path2).convert('RGB'))\n\n        if self.trans:\n            augments = self.trans(image=img1, image0=img2)\n            img1 = augments[\"image\"]\n            img2 = augments[\"image0\"]\n\n        return img1, img2","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-08-16T10:58:14.697089Z","iopub.execute_input":"2023-08-16T10:58:14.698688Z","iopub.status.idle":"2023-08-16T10:58:14.710997Z","shell.execute_reply.started":"2023-08-16T10:58:14.698654Z","shell.execute_reply":"2023-08-16T10:58:14.709889Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Discriminator","metadata":{}},{"cell_type":"code","source":"class CNNBlockDisc(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super().__init__()\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=4,\n                stride=stride,\n                padding=1,\n                bias=True,\n                padding_mode=\"reflect\",\n            ),\n            nn.InstanceNorm2d(out_channels),\n            nn.LeakyReLU(0.2),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels, features):\n        super().__init__()\n\n        self.initial = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                features[0],\n                4, 2, 1,\n                padding_mode=\"reflect\",\n            ), nn.LeakyReLU(0.2),\n        )\n\n        layers = []\n        for i in range(1, len(features)):\n            layers.append(CNNBlockDisc(\n                in_channels=features[i-1],\n                out_channels=features[i],\n                stride=(1 if i == len(features) - 1 else 2),\n            ))\n\n        layers.append(nn.Conv2d(\n            features[-1], 1, 4, 1, 1,\n            padding_mode=\"reflect\",\n        ))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.initial(x)\n        x = self.model(x)\n        return torch.sigmoid(x)\n\n\ndef test():\n    N = 32\n    x = torch.randn(N, 3, 256, 256)\n    model = Discriminator(3, [64, 128, 256, 512])\n    print(model(x).shape)\n\n\n# test()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-08-16T10:58:14.713410Z","iopub.execute_input":"2023-08-16T10:58:14.714931Z","iopub.status.idle":"2023-08-16T10:58:14.731558Z","shell.execute_reply.started":"2023-08-16T10:58:14.714898Z","shell.execute_reply":"2023-08-16T10:58:14.730383Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Generator","metadata":{}},{"cell_type":"code","source":"class CNNBlockGen(nn.Module):\n    def __init__(self, in_channels, out_channels, down=True, use_act=True,\n                 **kwargs):\n        super().__init__()\n\n        self.block = nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                padding_mode=\"reflect\",\n                **kwargs,\n            ) if down else nn.ConvTranspose2d(\n                in_channels,\n                out_channels,\n                **kwargs,\n            ),\n            nn.InstanceNorm2d(out_channels),\n            nn.ReLU(inplace=True) if use_act else nn.Identity(),\n        )\n\n    def forward(self, x):\n        return self.block(x)\n\n\nclass ResBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n\n        self.block = nn.Sequential(\n            CNNBlockGen(channels, channels,\n                     kernel_size=3, padding=1),\n            CNNBlockGen(channels, channels, use_act=False,\n                     kernel_size=3, padding=1),\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\n\nclass Generator(nn.Module):\n    def __init__(self, image_channels, num_features, num_residuals):\n        super().__init__()\n\n        self.initial = nn.Sequential(\n            nn.Conv2d(\n                image_channels,\n                num_features,\n                7, 1, 3,\n                padding_mode=\"reflect\",\n            ), nn.ReLU(inplace=True),\n        )\n\n        self.down_blocks = nn.ModuleList(\n            [\n                CNNBlockGen(num_features*1, num_features*2,\n                         kernel_size=3, stride=2, padding=1),\n                CNNBlockGen(num_features*2, num_features*4,\n                         kernel_size=3, stride=2, padding=1),\n            ]\n        )\n\n        self.residual_blocks = nn.Sequential(\n            *[ResBlock(num_features*4) for _ in range(num_residuals)]\n        )\n\n        self.up_blocks = nn.ModuleList(\n            [\n                CNNBlockGen(num_features*4, num_features*2, down=False,\n                         kernel_size=3, stride=2, padding=1, output_padding=1),\n                CNNBlockGen(num_features*2, num_features*1, down=False,\n                         kernel_size=3, stride=2, padding=1, output_padding=1),\n            ]\n        )\n\n        self.last = nn.Sequential(\n            nn.Conv2d(\n                num_features,\n                image_channels,\n                7, 1, 3,\n                padding_mode=\"reflect\",\n            ), nn.Tanh(),\n        )\n\n    def forward(self, x):\n        x = self.initial(x)\n        for layer in self.down_blocks:\n            x = layer(x)\n        x = self.residual_blocks(x)\n        for layer in self.up_blocks:\n            x = layer(x)\n        return self.last(x)\n\n\ndef test():\n    N = 32\n    x = torch.randn(N, 3, 256, 256)\n    model = Generator(3, 64, 9)\n    print(model(x).shape)\n\n\n# test()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-08-16T10:58:14.735664Z","iopub.execute_input":"2023-08-16T10:58:14.737554Z","iopub.status.idle":"2023-08-16T10:58:14.761849Z","shell.execute_reply.started":"2023-08-16T10:58:14.737519Z","shell.execute_reply":"2023-08-16T10:58:14.760721Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Cycle GAN","metadata":{}},{"cell_type":"code","source":"class CycleGAN:\n    def __init__(self, save=True, load=False, epochs=10):\n        self.DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() \\\n            else torch.device(\"cpu\")\n\n        self.SAVE = save\n        self.LOAD = load\n        self.EPOCHS = epochs\n\n        self.NUM_EPOCHS = 10\n        self.LEARNING_RATE = 1e-5\n        self.LAMBDA_CYCLE = 10.0\n        self.LAMBDA_IDENTITY = 0.0\n\n        self.CHECKPOINT_DSC_X = \"checkpoints/dscx.pth.tar\"\n        self.CHECKPOINT_DSC_Y = \"checkpoints/dscy.pth.tar\"\n        self.CHECKPOINT_GEN_X = \"checkpoints/genx.pth.tar\"\n        self.CHECKPOINT_GEN_Y = \"checkpoints/geny.pth.tar\"\n        self.IMG_SAVE_PATH = \"saved_images\"\n        \n        try:\n            os.mkdir(self.IMG_SAVE_PATH)\n            print(\"'Saved Images' Directory created.\")\n        except FileExistsError:\n            print(\"'Saved Images' Directory already exists.\")\n\n        IMAGE_CHANNELS = 3\n        DSC_FEATURES = [64, 128, 256, 512]\n        GEN_FEATURES = 64\n        NUM_RESIDUALS = 9\n\n        BATCH_SIZE = 1\n        NUM_WORKERS = 4\n        ROOT_PATH_1 = \"../input/gan-getting-started/photo_jpg\"\n        ROOT_PATH_2 = \"../input/gan-getting-started/monet_jpg\"\n\n        transforms = A.Compose(\n            [\n                A.Resize(width=256, height=256),\n                A.HorizontalFlip(p=0.5),\n                A.Normalize(\n                    mean=[0.5 for _ in range(IMAGE_CHANNELS)],\n                    std=[0.5 for _ in range(IMAGE_CHANNELS)],\n                    max_pixel_value=255,\n                ),\n                ToTensorV2(),\n            ],\n            additional_targets={\"image0\": \"image\"},\n        )\n\n        self.dscX = Discriminator(IMAGE_CHANNELS, DSC_FEATURES).to(self.DEVICE)\n        self.dscY = Discriminator(IMAGE_CHANNELS, DSC_FEATURES).to(self.DEVICE)\n        self.genX = Generator(IMAGE_CHANNELS, GEN_FEATURES,\n                              NUM_RESIDUALS).to(self.DEVICE)\n        self.genY = Generator(IMAGE_CHANNELS, GEN_FEATURES,\n                              NUM_RESIDUALS).to(self.DEVICE)\n\n        self.opt_dsc = optim.Adam(\n            list(self.dscX.parameters()) + list(self.dscY.parameters()),\n            lr=self.LEARNING_RATE,\n            betas=(0.5, 0.999),\n        )\n\n        self.opt_gen = optim.Adam(\n            list(self.genX.parameters()) + list(self.genY.parameters()),\n            lr=self.LEARNING_RATE,\n            betas=(0.5, 0.999),\n        )\n\n        self.l1 = nn.L1Loss()\n        self.mse = nn.MSELoss()\n\n        dataset = CustomDataset(\n            root1=ROOT_PATH_1,\n            root2=ROOT_PATH_2,\n            trans=transforms\n        )\n\n        self.dataloader = DataLoader(\n            shuffle=True,\n            pin_memory=True,\n            dataset=dataset,\n            batch_size=BATCH_SIZE,\n            num_workers=NUM_WORKERS,\n        )\n\n        self.gen_scaler = torch.cuda.amp.GradScaler()\n        self.dsc_scaler = torch.cuda.amp.GradScaler()\n\n    def train(self):\n        if self.LOAD:\n            self.load_model()\n\n        for epoch in range(self.EPOCHS):\n            self.train_model()\n\n            if self.SAVE:\n                self.save_model()\n\n    def train_model(self):\n        seed_everything()\n        Y_real_log, Y_fake_log = 0, 0\n        looper = tqdm(self.dataloader)\n\n        for idx, (X, Y) in enumerate(looper):\n            real_X, real_Y = X.to(self.DEVICE), Y.to(self.DEVICE)\n            \n            # Discriminator Training\n            with torch.cuda.amp.autocast():\n                fake_X = self.genX(real_Y)\n                dscX_real = self.dscX(real_X)\n                dscX_fake = self.dscX(fake_X)\n                dscX_real_loss = self.mse(\n                    dscX_real, torch.ones_like(dscX_real))\n                dscX_fake_loss = self.mse(\n                    dscX_fake, torch.zeros_like(dscX_fake))\n                dscX_loss = dscX_real_loss + dscX_fake_loss\n\n                fake_Y = self.genY(real_X)\n                dscY_real = self.dscY(real_Y)\n                dscY_fake = self.dscY(fake_Y)\n                dscY_real_loss = self.mse(\n                    dscY_real, torch.ones_like(dscY_real))\n                dscY_fake_loss = self.mse(\n                    dscY_fake, torch.zeros_like(dscY_fake))\n                dscY_loss = dscY_real_loss + dscY_fake_loss\n\n                dsc_loss = dscX_loss + dscY_loss\n\n                # For logging purposes\n                Y_real_log += dscY_real.mean().item()\n                Y_fake_log += dscY_fake.mean().item()\n\n            self.opt_dsc.zero_grad()\n            self.dsc_scaler.scale(dsc_loss).backward(retain_graph=True)\n            self.dsc_scaler.step(self.opt_dsc)\n            self.dsc_scaler.update()\n\n            # Generator Training\n            with torch.cuda.amp.autocast():\n                # Adversarial Loss\n                dscX_fake = self.dscX(fake_X)\n                dscY_fake = self.dscY(fake_Y)\n                genX_loss = self.mse(dscX_fake, torch.ones_like(dscX_fake))\n                genY_loss = self.mse(dscY_fake, torch.ones_like(dscY_fake))\n\n                # Cycle Loss\n                cycleX = self.genX(fake_Y)\n                cycleY = self.genY(fake_X)\n                cycleX_loss = self.l1(real_X, cycleX)\n                cycleY_loss = self.l1(real_Y, cycleY)\n\n                # Identity Loss (currently set to zero)\n                # identityX = self.genX(real_X)\n                # identityY = self.genY(real_Y)\n                # identityX_loss = self.l1(real_X, identityX)\n                # identityY_loss = self.l1(real_Y, identityY)\n\n                gen_loss = (\n                    genX_loss + genY_loss +\n                    (cycleX_loss + cycleY_loss) * self.LAMBDA_CYCLE\n                    # (identityX_loss + identityY_loss) * self.LAMBDA_IDENTITY\n                )\n\n            self.opt_gen.zero_grad()\n            self.gen_scaler.scale(gen_loss).backward()\n            self.gen_scaler.step(self.opt_gen)\n            self.gen_scaler.update()\n\n            # Saving images and logging\n            if idx % 100 == 0:\n                save_image(fake_X * 0.5 + 0.5,\n                           f\"{self.IMG_SAVE_PATH}/X{idx}.jpg\")\n                save_image(fake_Y * 0.5 + 0.5,\n                           f\"{self.IMG_SAVE_PATH}/Y{idx}.jpg\")\n\n            looper.set_postfix(\n                Y_real=Y_real_log / (idx + 1),\n                Y_fake=Y_fake_log / (idx + 1),\n            )\n\n    def load_model(self):\n        load_checkpoint(self.CHECKPOINT_DSC_X, self.dscX,\n                        self.opt_dsc, self.LEARNING_RATE, self.DEVICE)\n        load_checkpoint(self.CHECKPOINT_DSC_Y, self.dscY,\n                        self.opt_dsc, self.LEARNING_RATE, self.DEVICE)\n        load_checkpoint(self.CHECKPOINT_GEN_X, self.genX,\n                        self.opt_gen, self.LEARNING_RATE, self.DEVICE)\n        load_checkpoint(self.CHECKPOINT_GEN_Y, self.genY,\n                        self.opt_gen, self.LEARNING_RATE, self.DEVICE)\n\n    def save_model(self):\n        save_checkpoint(self.CHECKPOINT_DSC_X, self.dscX, self.opt_dsc)\n        save_checkpoint(self.CHECKPOINT_DSC_Y, self.dscY, self.opt_dsc)\n        save_checkpoint(self.CHECKPOINT_GEN_X, self.genX, self.opt_gen)\n        save_checkpoint(self.CHECKPOINT_GEN_Y, self.genY, self.opt_gen)","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-08-16T10:58:14.764184Z","iopub.execute_input":"2023-08-16T10:58:14.765704Z","iopub.status.idle":"2023-08-16T10:58:14.819114Z","shell.execute_reply.started":"2023-08-16T10:58:14.765671Z","shell.execute_reply":"2023-08-16T10:58:14.818117Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Execution","metadata":{}},{"cell_type":"code","source":"model = CycleGAN()\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T10:58:14.821792Z","iopub.execute_input":"2023-08-16T10:58:14.823111Z","iopub.status.idle":"2023-08-16T10:59:44.989161Z","shell.execute_reply.started":"2023-08-16T10:58:14.823079Z","shell.execute_reply":"2023-08-16T10:59:44.987359Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"'Saved Images' Directory already exists.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n  1%|          | 82/7038 [01:17<1:49:04,  1.06it/s, Y_fake=nan, Y_real=0.503]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m CycleGAN()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[6], line 95\u001b[0m, in \u001b[0;36mCycleGAN.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEPOCHS):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSAVE:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model()\n","Cell \u001b[0;32mIn[6], line 167\u001b[0m, in \u001b[0;36mCycleGAN.train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_gen\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_scaler\u001b[38;5;241m.\u001b[39mscale(gen_loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Saving images and logging\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:370\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]}]}